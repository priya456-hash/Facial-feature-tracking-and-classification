{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Facial feature tracking and classification with dlib.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOjSMfTm8s9VBjlpoxob4Ev",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/priya456-hash/Facial-feature-tracking-and-classification/blob/main/Facial_feature_tracking_and_classification_with_dlib.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "dlib is general purpose sofwtare library writting in programming lanaguage C++.We will be using it for understaning and finding human facial features from images and videos. dlib.net contains machine learning algorithms and tools for creating complex software in c++ to solve real world problems. it  is similar to opencv."
      ],
      "metadata": {
        "id": "9qrAkqXoIXsl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "landmarks which is being uploaded are like a pretrrained model, a database of a whole bunch of human faces of people from all over the world, male/female, different age groups and so forth. landmarks gain from iBUG"
      ],
      "metadata": {
        "id": "e09blxQwhv2l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install python3-tk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jB-RfpQSU3gj",
        "outputId": "b1531ed3-b205-406c-c2f3-b41284883f32"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "python3-tk is already the newest version (3.6.9-1~18.04).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 39 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### CREATE VIRTUAL DISPLAY ###\n",
        "!apt-get install -y xvfb # Install X Virtual Frame Buffer\n",
        "import os\n",
        "os.system('Xvfb :1 -screen 0 1600x1200x16  &')    # create virtual display with size 1600x1200 and 16 bit color. Color can be changed to 24 or 8\n",
        "os.environ['DISPLAY']=':1.0'    # tell X clients to use our virtual DISPLAY :1.0."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gey5aHYWVDI_",
        "outputId": "5209af9a-bc03-45f9-85b8-79981b5609d8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "xvfb is already the newest version (2:1.19.6-1ubuntu4.10).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 39 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# importing all required libraries\n",
        "import dlib\n",
        "import cv2\n",
        "import os \n",
        "\n",
        "from tkinter import filedialog\n",
        "from IPython import display\n",
        "\n",
        "import tkinter as tk\n",
        "root = tk.Tk()\n",
        "root.withdraw()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Ci5nxx7wgsrv",
        "outputId": "5cae0d3a-8961-49b4-e09a-52de891cd76e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "''"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "imgname = filedialog.askopenfilename(parent = root, initialdir = os.getcwd(), title = 'select image file...')\n",
        "\n",
        "img = imread(imgname)\n",
        "img.flags['WRITEABLE'] = True\n",
        "annotated = img.copy()\n",
        "\n"
      ],
      "metadata": {
        "id": "pY5KR9aAjHmD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictor_path = \"./content/shape_predictor_68_face_landmarks.dat\"\n",
        "detector = dlib.get_frontal_face_detector()\n",
        "predictor = dlib.shape_predictor(predictor_path)\n",
        "font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "dets = detector(img,1)\n",
        "print(\"Number of faces detected: {}\".format(len(dets)))\n",
        "for k, d in enumerate(dets):\n",
        "  print(\"Detection {}: left:{} Top: {} Right: {} Bottom: {}\".format(k, d.left(), d.top(), d.right(), d.bottom()))\n",
        "  shape = predictor(img, d)\n",
        "  print(\"Part 0: {}, Part1: {}...\".format(shape.part(0), shape.part(1)))\n",
        "  head_width = shape.part(16).x-shape.part(0).y\n",
        "  fontsize = head_width/650\n",
        "  for pt in range(68):\n",
        "    x,y = shape.part(pt).x, shape.part(pt).y\n",
        "    annotated = cv2.putText(annotated, str(pt), (x,y), font, fontsize, (255,255,255),2,cv2.LINE_AA)\n",
        "    figure(figsize = (8,6))\n",
        "    imshow(annotated)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "PDAPv37JXujK",
        "outputId": "9d32d16c-11e0-41d8-dc16-e423640f34ca"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-2a06d0d2d086>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpredictor_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"./content/shape_predictor_68_face_landmarks.dat\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdetector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_frontal_face_detector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mpredictor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape_predictor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictor_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mfont\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFONT_HERSHEY_SIMPLEX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdetector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'dlib' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Faces in VIDEOS"
      ],
      "metadata": {
        "id": "EILdEM88a6sD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# importing all required libraries\n",
        "import dlib\n",
        "import cv2\n",
        "import os \n",
        "\n",
        "from tkinter import filedialog\n",
        "from IPython import display\n",
        "\n",
        "import tkinter as tk\n",
        "root = tk.Tk()\n",
        "root.withdraw()\n"
      ],
      "metadata": {
        "id": "CdSDB0Bpau8K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictor_path = \"./shape_predictor_68_face_landmarks.dat\"\n",
        "detector = dlib.get_frontal_face_detector()\n",
        "predictor = dlib.shape_predictor(predictor_path)"
      ],
      "metadata": {
        "id": "wjxh9yoha5nq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#cap = cv2.VideoCapture(0)\n",
        "cap = cv2.VideoCapture('./rollerc.mp4')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "id": "eQsHAjazbD6C",
        "outputId": "139038d2-bc6d-4cf4-b45d-6781dad4dbda"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-1bdfab89cb9f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#cap = cv2.VideoCapture(0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVideoCapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./rollerc.mp4'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'cv2' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "font = cv2.FONT_HERSHEY_SIMPLEX"
      ],
      "metadata": {
        "id": "w6ajJj2ecB_T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imgname = filedialog.askopenfilename(parent = root, initialdir = os.getcwd(), title = 'select image file...')\n",
        "img = imread(imgname)\n"
      ],
      "metadata": {
        "id": "uQMXVOkFoDxW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "yNDYoDUGgf0F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "while(True):\n",
        "  ret, img = cap.read\n",
        "  img.flags['writeable']=True\n",
        "  try:\n",
        "    dets = detector(img,1)\n",
        "    shape = predictor(img, dets[0])\n",
        "  except:\n",
        "      print('no face detected', end='\\r')\n",
        "      cap.release()\n",
        "      break\n",
        "      annotated = img.copy()\n",
        "      shape = predictor(img, dets[0])\n",
        "\n",
        "      head_width = shape.part(16).x-shape.part(0).x\n",
        "      fontsize = head_width/650\n",
        "\n",
        "      for pt in range(68):\n",
        "\n",
        "        x,y = shape.part(pt).x, shape.part(pt).y\n",
        "\n",
        "        annotated = cv2.putText(annotated, str(pt), (x,y), font, fontsize, (255,255,255),2,cv2.LINE_AA)\n",
        "\n"
      ],
      "metadata": {
        "id": "ofskpAVfgISY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(img)"
      ],
      "metadata": {
        "id": "pKt-23PDmuuq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(annotated)"
      ],
      "metadata": {
        "id": "4olXvZOcl31-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pylab import *"
      ],
      "metadata": {
        "id": "CtyyS3eNltE9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imshow(annotated)"
      ],
      "metadata": {
        "id": "hpyK-dEelkcd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = imshow(cv2.cvtColor(annotated, cv2.COLOR_BGR2RGB))"
      ],
      "metadata": {
        "id": "W8kRn59VlDxS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "MNCPRHpahKD5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}